<html>
<head>
<title>Proxying to Microservices - Read Chinese Online</title>
<link rel="stylesheet" type="text/css" href="/rco/assets/styles.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/prismjs@1.9.0/themes/prism-okaidia.min.css">
<script src="https://cdn.jsdelivr.net/npm/prismjs@1.9.0/prism.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/prismjs@1.9.0/plugins/remove-initial-line-feed/prism-remove-initial-line-feed.min.js"></script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/prismjs@1.9.0/plugins/unescaped-markup/prism-unescaped-markup.min.css">
<script src="https://cdn.jsdelivr.net/npm/prismjs@1.9.0/plugins/unescaped-markup/prism-unescaped-markup.min.js"></script>

</head>
<!-- body is hidden until initial front end transforms are applied -->
<body style="display: none;">

<div id="wordbox">
    <div id="chinese"></div>
    <div id="pinyin"></div>
    <div id="meaning"></div>
</div>

<div style="background-color: rgb(240,240,240); padding-top: 10px; padding-bottom: 10px;">
    <div class="container">
        <a href="/rco/"><strong>中文</strong> Read Chinese Online</a>
    </div>
</div>



<div class="container">
    <h1 class="article-title">Proxying to Microservices</h1>
    <h2 class="article-description">How to set up a reverse proxy for Docker microservices</h2>
    

    <p>
        <strong>Date:</strong> 2017-12-19 &nbsp;&nbsp;&nbsp;
        <strong>Tags:</strong> <a href="/rco/tags/docker.html">docker</a> <a href="/rco/tags/nginx.html">nginx</a> <a href="/rco/tags/traefik.html">traefik</a> <a href="/rco/tags/microservices.html">microservices</a> 
    </p>
    <hr>

</div>
<div class="container">
    

<p>Docker makes it really easy to build and deploy your application as a set of microservices, and send data back and forth between these. If they are on the same Docker <strong>network</strong>, they can all talk to each other directly, since the containers are automatically configured with host entries for the names of the other containers on their networks.</p>

<p>But what if you want the various microservices to have endpoints to the Internet? For example, if you have modern client side front end such as an Angular application, or a mobile app, you will need this. The front end app, running on the user's computer, will make HTTP requests to your various back end microservices, and as such you will need endpoints for it to connect to. Ideally with some kind of nice, semantic address, such as <strong>thesite.com/themicroservice</strong>, or <strong>themicroservice.thesite.com</strong>. Now let's look at some ways to go about this.</p>

<h2>Solution #1 - No Reverse Proxy, Just Expose Ports</h2>
<p>A simple solution to this problem is to simply expose the microservices on separate ports. This is supported out of the box in Docker, you simply run a bunch of Docker services, and have each expose a specific port, such as <strong>thesite.com:10001</strong>. The downside is that the addresses will be cryptic, but on the other hand, if it's documented properly, and it's meant for a machine to read, maybe that's not a big deal?</p>

<h2>Solution #2 - Nginx Reverse Proxy</h2>
<p>Nginx has become a lot of people's go-to tool for serving static files, and for proxying to other services. It's really fast and powerful - you put it in its own Docker container along your other microservices, and you can make a route proxy to somewhere else with just a few lines, like this:</p>

<pre><code class="language-nginx">
location /some-path/ {
    proxy_pass http://some-service:3000/;
}
</code></pre>

<p>With a block like this in the place in your Nginx configuration, when a user hits <strong>thesite.com/some-path</strong>, Nginx will make sure to route the request to the correct Docker container. The <strong>some-service</strong> host name is known inside the container, since Docker will make host entries for the containers on the same Docker network. So like this, you can make entries for each microservice, and thereby give a nice, descriptive URL path for each of them.</p>

<p>Unfortunately, there's a big problem with this approach. Nginx will do a DNS lookup of the proxy_pass address upon launch,and then just cache the address forever, expecting it to never change. This means that if the IP address changes, the proxy will not work anymore (you'll get a <strong>502 - Bad Gateway</strong>), and also, if the address cannot be resolved when launching, Nginx won't even start, it will just give you an error and shut down.</p>

<p>This is clearly not very ideal for a microservices architecture. It means you will have to make sure that your Nginx proxy first launches when all your other services are already up and running, and it also means you will have to restart the Nginx if one of the other microservices was restarted.</p>

<p>Dynamic DNS resolution is a selling point of the premium version of Nginx, Nginx Plus, but you actually don't need Nginx Plus to be able do this (contrary to what the Nginx people might want you to believe... :) ). The trick is that you must set the proxy_pass address as a variable, since Nginx treats variables differenty from static configuration:</p>

<pre><code class="language-nginx">
location /some-path/ {
    resolver 127.0.0.11 valid=20s;
    set $backend http://some-service:3000/;
    proxy_pass $backend;
}
</code></pre>

The <strong>resolver</strong> directive is necessary for this to work - it specifies the DNS server from which we will resolve the name. 127.0.0.1 is your Docker's DNS, so it knows where to find your containers. The <strong>valid</strong> attribute specifies how much time must pass before Nginx will fetch new DNS info upon receiving a request.

<p>This is starting to look like something, but there is one final issue: The proxy_pass directive acts a bit funny when fed a variable like this - it will no longer send the whole request URI through to the proxied endpoint. So if you made a request to <strong>thesite.com/some-service/products?id=p99</strong>, everything after <strong>thesite.com/some-service</strong> would be stripped off the request to the Docker container, and you'd get back a result from the root path. This is obviously a dealbreaker!

<p>Luckily, we can take care of this with a bit of regex magic:</p>

<pre><code class="language-nginx">
location ~ ^/some-path(/(.*))?$ {
    resolver 127.0.0.11 valid=20s;
    set $address http://some-service:3000/;
    proxy_pass $address/$2;
}
</code></pre>

<p>The regular expression matches <strong>/some-path</strong>, and anything that starts with <strong>/some-path/</strong>. The <strong>$2</strong> stores the string matched in the second set of parentheses in the regular expression - so it will contain anything that comes after <strong>/some-path/</strong>. We append that at the end of the address to which we proxy. And like that, we now have a fully functioning Nginx reverse proxy that refreshes its DNS info every 20 seconds!</p>

<h2>Solution #2 - Dynamic Reverse Proxy: Træfik</h2>

<p>Finally, let's look at another, and easily the coolest, approach. <strong>Træfik</strong> is a modern reverse proxy, created especially with the purpose of dynamically proxying traffic to microservice containers. To use it with Docker, you can just Deploy a container made from the official Træfik Docker image, with some configuration, alongside your other microservices.</p>

<p>Check out this Docker Compose file specifying two microservices. (It's a modified version of an example from Træfik's Github)</p>

<pre><code class="language-docker-compose">
version: '3'
services:
  traefik:
    image: traefik
    command: -c /dev/null --web --docker --docker.domain=docker.localhost --logLevel=DEBUG
    ports:
      - "80:80"
      - "8080:8080"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock

  whoami1:
    image: emilevauge/whoami
    labels:
      - "traefik.backend=whoami1"
      - "traefik.frontend.rule=PathPrefixStrip: /service-1"

  whoami2:
    image: emilevauge/whoami
    labels:
      - "traefik.backend=whoami2"
      - "traefik.frontend.rule=PathPrefixStrip: /service-2"
</code></pre>

<p>This file will spin up three services: one Træfik service listening on port 80 and 8080, and two services built from the same 'whoami' image, which only serves some info about itself.</p>

<p>Træfik's 8080 port exposes an administration panel, which is a cool feature in its own right. Port 80, naturally, is the one meant as an endpoint to the world. In this example we've got two microservices running, one would be on <strong>thesite.com/service-1</strong>, and the other at <strong>thesite.com/service-2</strong>.</p>

<p>Notice how the Træfik service does not need be configured to look for the other services at all. The services themselves can take hand of their own routing, simply by specifying a label on the container. Træfik will read these labels and update its proxying accordingly as services come and go (there's a bunch of different rule types to choose from, you can f.ex. easily deploy the microservices at subdomains instead of subpaths of the URL).</p>

<p>This is very powerful. The lack of need for centralized configuration leads to a really elegant and decoupled architecture. Træfik can also renew your SSL certificates automatically! Træfik is awesome.</p>
</div>



<script src="https://code.jquery.com/jquery-3.2.1.js"></script>
<script src="/rco/assets/js/tongwen/tongwen-ts.js"></script>
<script src="/rco/assets/js/rco.js"></script>

</body>
</html>